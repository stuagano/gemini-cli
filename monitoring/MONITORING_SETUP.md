# Gemini Enterprise Architect - Complete Monitoring & Observability Setup

This comprehensive monitoring system provides complete observability for the Gemini Enterprise Architect agent system, including metrics, logs, traces, and business intelligence.

## üéØ Overview

The monitoring stack includes:

### üìä **Monitoring Dashboards**
- **Agent Performance**: Real-time agent metrics, response times, error rates
- **DORA Metrics**: Deployment frequency, lead time, MTTR, change failure rate
- **Killer Demo Findings**: Scaling issue detection and optimization impact
- **Scout Metrics**: Duplicate detection accuracy and indexing performance
- **System Health**: Infrastructure health and resource utilization
- **Business Impact**: Cost monitoring, ROI tracking, and productivity metrics

### üö® **Alerting & SLOs**
- **157 Alert Rules**: Covering critical issues, performance degradation, and business impact
- **Multi-Window Burn Rate Alerts**: Sophisticated SLO violation detection
- **Error Budget Tracking**: Proactive alerting before SLO violations
- **Team-Based Routing**: Alerts route to appropriate teams (Platform, Security, Intelligence, etc.)

### üìù **Structured Logging**
- **JSON Structured Logs**: Consistent, searchable log format across all components
- **Centralized Aggregation**: Loki-based log collection and analysis
- **Correlation IDs**: Request tracking across distributed components
- **Log-Based Metrics**: Automatic metric generation from log patterns

### üîç **Distributed Tracing**
- **OpenTelemetry Integration**: Complete request flow visibility
- **Multi-Agent Workflows**: Trace complex agent interactions
- **Performance Profiling**: Code-level performance insights
- **Custom Metrics**: Business-specific performance indicators

## üöÄ Quick Start

### Prerequisites
- Docker & Docker Compose
- 8GB+ RAM available
- 20GB+ disk space

### 1. Deploy Monitoring Stack
```bash
cd monitoring
./deployment/deploy-monitoring.sh
```

### 2. Access Dashboards
- **Grafana**: http://localhost:3000 (admin/gemini_admin_2024)
- **Prometheus**: http://localhost:9090
- **Jaeger**: http://localhost:16686
- **Alertmanager**: http://localhost:9093

### 3. Configure Your Application
```python
# Add to your requirements.txt
prometheus-client
opentelemetry-api
opentelemetry-sdk
opentelemetry-exporter-otlp

# In your FastAPI application
from monitoring.telemetry.tracing import initialize_tracing
from monitoring.logging.structured_logging import AgentLogger

# Initialize tracing
tracer = initialize_tracing("your-service", "1.0.0")

# Use structured logging
logger = AgentLogger("your-service")
logger.info("Service started", service_version="1.0.0")
```

## üìä Dashboard Details

### Agent Performance Dashboard
**File**: `dashboards/agent-performance.json`

**Key Metrics**:
- Agent request rate and volume by type
- Response time percentiles (95th, 99th)
- Error rate breakdown by agent and error type
- Active sessions and queue sizes
- Knowledge base query performance

**Alerts**: Response time > 2s, Error rate > 5%, Queue backlog > 100

### DORA Metrics Dashboard
**File**: `dashboards/dora-metrics.json`

**Key Metrics**:
- **Deployment Frequency**: Deployments per day/week
- **Lead Time**: Code commit to production deployment
- **MTTR**: Mean time to recovery from incidents
- **Change Failure Rate**: Percentage of deployments causing failures

**Business Value**: Measures DevOps performance and delivery efficiency

### Killer Demo Findings Dashboard
**File**: `dashboards/killer-demo-findings.json`

**Key Metrics**:
- Scaling issues detected by severity
- Cost savings potential ($ amount)
- Performance impact (% improvement)
- Detection accuracy and false positive rates
- Top hotspots and optimization recommendations

**Business Value**: Tracks ROI from performance optimizations

### Scout Metrics Dashboard
**File**: `dashboards/scout-metrics.json`

**Key Metrics**:
- Files indexed per minute
- Duplicate detection rate and accuracy
- Language distribution analysis
- Function complexity trending
- Memory usage by index type

**Business Value**: Code quality and technical debt monitoring

### System Health Dashboard
**File**: `dashboards/system-health.json`

**Key Metrics**:
- CPU, memory, disk utilization
- Database connection pools
- Container health and restarts
- Network I/O patterns
- Error log volume

### Business Impact Dashboard
**File**: `dashboards/business-impact.json`

**Key Metrics**:
- Total cost savings achieved
- Infrastructure costs by service
- Developer productivity metrics
- ROI from optimizations
- Time to resolution tracking

## üö® Alerting Configuration

### Alert Categories

#### Critical Alerts (PagerDuty)
- **Agent Server Down**: Service unavailable
- **High Error Rate**: >5% error rate for 5 minutes
- **Database Connection Failures**: Any connection failures
- **Memory/CPU Exhaustion**: >95% utilization

#### Warning Alerts (Slack)
- **High Response Time**: 95th percentile >2 seconds
- **Queue Backlog**: >100 requests pending
- **Low Detection Accuracy**: Scout accuracy <95%
- **Resource Usage**: >80% CPU/memory utilization

#### Business Alerts (Email)
- **Scaling Issues Detected**: Critical performance problems found
- **Cost Anomalies**: 50% higher costs than baseline
- **SLO Violations**: Error budget exhaustion warnings

### Alert Routing
```yaml
# Platform Team: Infrastructure and system alerts
- Team: platform
  Channels: [slack-platform, pagerduty-critical]
  
# Intelligence Team: Agent and AI-related alerts  
- Team: intelligence
  Channels: [slack-intelligence, email-intelligence]
  
# Security Team: Guardian and security alerts
- Team: security
  Channels: [slack-security, email-security]
  
# Optimization Team: Killer Demo and cost alerts
- Team: optimization  
  Channels: [slack-optimization, email-optimization]
```

## üìù Logging Strategy

### Structured Logging Format
```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "service": "agent-server",
  "component": "analyst-agent",
  "message": "Agent request completed",
  "request_id": "req_123456",
  "agent_type": "analyst",
  "action": "analyze_code",
  "duration_ms": 1234,
  "success": true,
  "user_id": "user_789",
  "session_id": "session_abc"
}
```

### Log Aggregation Rules
- **Error Rate Monitoring**: Real-time error pattern detection
- **Performance Tracking**: Response time analysis from logs
- **Business Logic Monitoring**: Custom event tracking
- **Security Monitoring**: Authentication and authorization events

### Log Retention
- **High-frequency logs**: 7 days
- **Error logs**: 30 days  
- **Audit logs**: 90 days
- **Business metrics**: 1 year

## üîç Distributed Tracing

### Trace Coverage
- **Agent Requests**: Complete request lifecycle
- **Scout Operations**: File indexing and duplicate detection  
- **Guardian Validations**: Security and compliance checks
- **Knowledge Queries**: RAG system performance
- **Database Operations**: Query performance and connection health

### Custom Spans
```python
from monitoring.telemetry.tracing import trace_operation

@trace_agent_request("analyst")
async def analyze_code(request):
    with trace_operation("code_analysis", {"file_count": len(files)}):
        # Analysis logic
        return results
```

### Trace Sampling
- **Critical Paths**: 100% sampling
- **Agent Operations**: 50% sampling  
- **Normal Requests**: 10% sampling
- **Error Traces**: 100% sampling

## üéØ Service Level Objectives (SLOs)

### Agent Performance SLOs
- **Response Time**: 99.5% of requests < 2 seconds
- **Availability**: 99.9% success rate
- **Error Rate**: <0.5% error rate

### Scout Indexing SLOs  
- **Indexing Success**: 99% of files indexed successfully
- **Processing Speed**: 95% of files processed < 1 second
- **Detection Accuracy**: 95% duplicate detection accuracy

### System Infrastructure SLOs
- **Uptime**: 99.95% system availability 
- **Database**: 99.9% database availability
- **API Gateway**: 99% of requests < 500ms

### Business SLOs
- **Cost Optimization**: 80% of recommendations implemented
- **Developer Productivity**: >75% of baseline productivity
- **Issue Resolution**: 90% of issues resolved < 24 hours

## üí∞ Cost Monitoring

### Infrastructure Costs
- **Service-based Attribution**: Cost per agent, service, team
- **Resource Efficiency**: Utilization vs. allocated resources
- **Scaling Cost Impact**: Auto-scaling cost implications
- **Optimization ROI**: Savings from performance improvements

### Cost Optimization Alerts
- **Anomaly Detection**: 50% cost increase triggers
- **Waste Detection**: Underutilized resources identification
- **Budget Thresholds**: Monthly budget violation warnings

## üîß Configuration

### Environment Variables
```bash
# Core Configuration  
ENVIRONMENT=production
NAMESPACE=gemini-monitoring

# Database
POSTGRES_PASSWORD=secure_password

# Alerting
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK
PAGERDUTY_INTEGRATION_KEY=your_pagerduty_key

# External Monitoring
HONEYCOMB_API_KEY=your_honeycomb_key
```

### Prometheus Configuration
- **Scrape Interval**: 15s for agent metrics, 30s for system metrics
- **Retention**: 90 days, 50GB storage limit
- **External Labels**: Environment, monitor tags for multi-cluster setup

### Grafana Configuration
- **Data Sources**: Prometheus, Loki, Jaeger, Alertmanager
- **Dashboard Provisioning**: Automatic dashboard deployment
- **Alert Channels**: Slack, email, PagerDuty integration

## üöÄ Deployment Options

### Docker Compose (Recommended for Development)
```bash
cd monitoring
./deployment/deploy-monitoring.sh
```

### Kubernetes (Production)
```bash
kubectl apply -f k8s/monitoring/
helm install grafana grafana/grafana -f grafana-values.yaml
helm install prometheus prometheus-community/kube-prometheus-stack
```

### Cloud Managed Services
- **AWS**: CloudWatch, X-Ray, Elasticsearch
- **GCP**: Cloud Monitoring, Cloud Trace, Cloud Logging  
- **Azure**: Azure Monitor, Application Insights

## üìä Performance Benchmarks

### Expected Resource Usage
- **Prometheus**: 2-4GB RAM, 10GB/month storage per 1K metrics
- **Grafana**: 512MB RAM, minimal storage
- **Loki**: 1-2GB RAM, 5GB/month storage per 10GB logs
- **Jaeger**: 1GB RAM, 2GB/month storage per 1M spans
- **OpenTelemetry Collector**: 512MB RAM, minimal overhead

### Scaling Guidelines
- **<10K requests/day**: Single-node deployment sufficient
- **10K-100K requests/day**: Clustered Prometheus, external storage
- **>100K requests/day**: Dedicated monitoring cluster, federated setup

## üîí Security Considerations

### Access Control
- **Grafana RBAC**: Team-based dashboard access
- **Prometheus**: Read-only external access
- **Alert Channels**: Encrypted webhook delivery
- **Log Data**: PII scrubbing and retention policies

### Network Security
- **TLS Encryption**: All inter-service communication
- **Network Policies**: Restricted service-to-service access
- **Firewall Rules**: External access control
- **VPN/Bastion**: Secure management access

## üõ†Ô∏è Troubleshooting

### Common Issues

#### High Memory Usage
```bash
# Check Prometheus memory usage
kubectl top pods -n monitoring
# Reduce retention or increase resources
helm upgrade prometheus --set prometheus.prometheusSpec.retention=30d
```

#### Missing Metrics
```bash
# Check Prometheus targets
curl http://localhost:9090/api/v1/targets
# Verify service discovery
kubectl get servicemonitor -n monitoring
```

#### Alert Fatigue
```bash
# Review alert frequency
curl http://localhost:9093/api/v1/alerts
# Adjust thresholds in prometheus-alerts.yml
```

### Performance Tuning
- **Query Optimization**: Use recording rules for complex queries
- **Storage Optimization**: Enable compression, optimize retention
- **Network Optimization**: Use local storage for high-throughput metrics

## üîÑ Maintenance

### Regular Tasks
- **Weekly**: Review alert noise and adjust thresholds
- **Monthly**: Cleanup old dashboards and unused metrics
- **Quarterly**: Review SLO targets and business metrics
- **Annually**: Capacity planning and infrastructure scaling

### Backup Strategy
```bash
# Backup Prometheus data
kubectl exec prometheus-0 -- tar czf /backup/prometheus-$(date +%Y%m%d).tar.gz /prometheus

# Backup Grafana dashboards  
kubectl get configmap grafana-dashboards -o yaml > grafana-backup.yaml

# Backup alert rules
kubectl get prometheusrule -o yaml > alerts-backup.yaml
```

## üìö Additional Resources

### Documentation
- **Prometheus**: https://prometheus.io/docs/
- **Grafana**: https://grafana.com/docs/
- **OpenTelemetry**: https://opentelemetry.io/docs/
- **Loki**: https://grafana.com/docs/loki/

### Best Practices
- **The RED Method**: Rate, Errors, Duration
- **The USE Method**: Utilization, Saturation, Errors  
- **Four Golden Signals**: Latency, Traffic, Errors, Saturation
- **SRE Principles**: Error budgets, SLO/SLI design

### Community
- **Grafana Community**: https://community.grafana.com/
- **Prometheus Community**: https://prometheus.io/community/
- **CNCF Slack**: #prometheus, #grafana, #opentelemetry channels

---

## üìû Support

For questions about this monitoring setup:
1. **Check the logs**: `./deployment/deploy-monitoring.sh logs`
2. **Review alert status**: http://localhost:9093
3. **Validate metrics**: http://localhost:9090/targets
4. **Test dashboards**: http://localhost:3000

**This monitoring system provides production-grade observability for the Gemini Enterprise Architect, enabling data-driven decisions and proactive issue resolution.**